{"cells":[{"cell_type":"markdown","metadata":{"id":"3tfH0vWdfn4w"},"source":["# **Scopo del Progetto**\n","\n","Lo scopo del progetto è quello di creare un servizio meteorologico in tempo reale, che permetta di visualizzare i dati meteo provenienti da più fonti pubbliche (con classificazione e previsione dei dati).\n","Al progetto abbiamo integrato (lato Spark) una funzionalità legata alla classificazione delle immagini che, in caso di immagine con possibile pioggia invia un messagio ad un canale telegram (gestito da un bot telegram), mentre nel caso in cui l'immagine sia considerata non valida invia una richiesta di reset al driver selenium lato producer. \n","Nel progetto verranno utilizzati i seguenti applicativi:\n","\n","\n","*   Selenium Python\n","*   Fluentd\n","*   Apache Kafka\n","*   Apache Spark\n","*   Elasticsearch\n","*   Kibana\n","\n","# **Breve descrizione**\n","\n","- ***Selenium Python***\n","Per l'estrazione dei dati dalle fonti web pubbliche abbiamo deciso di utilizzare degli script in Python; in particolare abbiamo deciso di utilizzare la libreria Selenium Python: questa simula l'interazione umana con un browser web (click su un link, screenshot, etc..).\n","\n","- ***Fluentd***\n","Fluentd è un software Open Source di data injestion, che consente di unificare la raccolta ed il consumo dei dati per una loro migliore comprensione ed utilizzo. Garantisce che i dati ottenuti dagli script python non vengano persi in caso di inoperatività di parti del sistema. Al suo interno vengono utilizzati i plugin nativi per l'inserimento dei dati provenienti dagli script Python, ed inoltre viene integrato un plugin per l'instradamento degli stessi verso Apache Kafka.\n","\n","- ***Apache Kafka***\n","Kafka è una piattaforma Open Source di stream processing a bassa latenza ed alta velocità per la gestione di feed dati in tempo reale. E' in grado di ottenere dati da molteplici fonti e di instradarle su differenti destinazioni. Nel progetto, Kafka ottiene i dati da Fluentd, non effettua alcun processing su di essi, e li invia ad Apache Spark. Garantisce la resilienza dei dati e che questi arrivino a Spark nello stesso ordine in cui vengono ottenuti.\n","\n","- ***Apache Spark***\n","Spark è un framework Open Source per il calcolo distribuito. Permette l'esecuzione di data engineering, machine learning, data science in locale o su cluster. Consente l'uso di vari linguaggi di programmazione e l'integrazione di software di terze parti (Elasticsearch), attraverso appositi plugin.\n","Nel progetto i dati provenienti da Kafka vengono letti attraverso il meccanismo di structured streaming, in tempo reale, con l'integrazione di un plugin Kafka.\n","I dati ottenuti verranno inseriti in un dataframe, verrà effettuata un'operazione di data regression su di essi in modo tale da ottenere una previsione statistica; in seguito verranno indicizzati su Elasticsearch e salvati in modo permanente sul filesystem locale.\n","Le immagini ottenute verranno inserite in un dataframe differente, verranno sottoposte ad un processo di image classification per stabilire se siano considerate \"valide\" e la classificazione ottenuta verrà indicizzata su Elasticsearch.\n","Nel caso l'immagine venga valutata come nuvoloso (il modello in uso permette correttamente di valutare solo 2 stati: valido e nd), dopo la seconda valutazione nuvoloso invia una messaggio al canale telegram gestito dal bot.\n","Nel caso l'immagine venga valutata nd, cioè non valida, viene inviata una richiesta di reset al producer python, che da Spark viene inviata a Kafka (topic restart_request) con valore \"true\", indicante di ricaricare il driver selenium relativo allo scraping dell'immagine meteo. Nel caso l'immagine sia considerata valida Spark invia comunque dati attraverso Kafka al producer python indicando la richiesta di reset come \"false\".\n","\n","- ***Elasticsearch***\n","Elasticsearch è un server di ricerca, con capacità Full Text, con supporto ad architetture distribuite. Le informazioni vengono gestite come documenti JSON.\n","Tutti i dati trattati, che verranno successivamente visualizzati su Kibana, vengono indicizzati su Elasticsearch in modo tale da poter effettuare delle interrogazioni (query) in maniera efficiente.\n","\n","- ***Kibana***\n","Kibana è un software di dashboard per la visualizzazione dei dati contenuti in Elasticsearch. Permette agli utenti di creare presentazioni dei dati sottoforma di grafici, tabelle, Canvas, e così via. Nel progetto si fa uso di alcuni grafici che mostrano i dati storici relativi alle rilevazioni, delle tabelle che mostrano le previsioni dei dati e le classificazioni delle immagini e dei grafici che mostrano i dati giornalieri.\n","\n","<br>\n","<br> \n","\n","<p align=\"center\">\n","    <img src=\"gitData/meme.png\" alt=\"meme\"/>\n","</p>"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOp7KIy/l6MKBxbHCMgTgbF","collapsed_sections":[],"name":"WebMeteo.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
